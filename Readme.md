# Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning

[![arXiv](https://img.shields.io/badge/arXiv-2402.13950-b31b1b.svg)](https://arxiv.org/abs/2402.13950)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

Official implementation of FRODO (Framework for Faithful Reasoning Over Deliberate Output).

**Paper**: [Making Reasoning Matter (EMNLP 2024)](https://arxiv.org/abs/2402.13950)  
**Authors**: Debjit Paul, Robert West, Antoine Bosselut, Boi Faltings

## Installation

```bash
git clone https://github.com/Causal_CoT.git
cd Causal_CoT
pip install -r requirements.txt
```

**Requirements**: Python ≥ 3.8, PyTorch ≥ 2.0.0

## Quick Start

### Run Tests
```bash
cd src
python test_frodo.py
```

### Train FRODO
```bash
cd src
python train_frodo.py
```

### Use in Your Code

```python
from transformers import AutoModelForSeq2SeqLM, AutoTokenizer
from frodo import FRODO, FRODOConfig

# Configure
config = FRODOConfig(
    model_name="google/flan-t5-large",
    beta=0.1,              # DPO temperature
    lambda_lm=1.0,         # Language model loss weight
    lambda_ie=1.0,         # Indirect effect loss weight
    lambda_margin=1.0,     # Margin ranking loss weight
)

# Load models
tokenizer = AutoTokenizer.from_pretrained(config.model_name)
inference_model = AutoModelForSeq2SeqLM.from_pretrained(config.model_name)
reasoning_model = AutoModelForSeq2SeqLM.from_pretrained(config.model_name)

# Create FRODO
frodo = FRODO(inference_model, reasoning_model, config)

# Train Phase 1: Inference Module
from src.frodo import DPODataset
from torch.utils.data import DataLoader

dpo_dataset = DPODataset(dpo_data, tokenizer)
dpo_dataloader = DataLoader(dpo_dataset, batch_size=8)
optimizer = torch.optim.AdamW(frodo.inference_module.parameters(), lr=5e-5)
frodo.train_inference_module(dpo_dataloader, num_epochs=3, optimizer=optimizer)

# Train Phase 2: Reasoning Module
from src.frodo import ReasoningDataset

reasoning_dataset = ReasoningDataset(reasoning_data, tokenizer)
reasoning_dataloader = DataLoader(reasoning_dataset, batch_size=8)
optimizer = torch.optim.AdamW(frodo.reasoning_module.parameters(), lr=5e-5)
frodo.train_reasoning_module(reasoning_dataloader, num_epochs=3, optimizer=optimizer)

# Inference
question = "Does a banana have more protein than an apple?"
reasoning, answer = frodo.generate_reasoning_and_answer(question, tokenizer)
```

## Data Format

### For Inference Module (DPO)

```python
dpo_data = [
    {
        'question': 'Does a banana have more protein than an apple?',
        'preferred_reasoning': 'Step 1: Banana has 1.3g protein per 100g. Step 2: Apple has 0.3g. Step 3: 1.3 > 0.3.',
        'dispreferred_reasoning': 'Step 1: Bananas are 0.3g protein per 100g. Step 2: Apple has 1.3g. Step 3: 1.3 > 0.3.',
    },
]
```

### For Reasoning Module

```python
reasoning_data = [
    {
        'question': 'Does a banana have more protein than an apple?',
        'reasoning': 'Step 1: Banana has 1.3g protein per 100g. Step 2: Apple has 0.3g. Step 3: 1.3 > 0.3.',
        'answer': 'Yes',
        'counterfactual_reasoning': 'Step 1: Bananas are 0.3g protein per 100g. Step 2: Apple has 1.3g. Step 3: 1.3 > 0.3.',
    },
]
```

## Repository Structure

```
Causal_CoT/
├── src/                     # FRODO implementation
│   ├── frodo.py            # Main framework
│   ├── train_frodo.py      # Training script
│   └── test_frodo.py       # Tests
├── requirements.txt
└── README.md
```

## Datasets

| Dataset | Type | Links |
|---------|------|-------|
| **StrategyQA** | Multi-hop QA | [Paper](https://arxiv.org/abs/2101.02235), [Data](https://allenai.org/data/strategyqa) |
| **QuaRel** | Qualitative Reasoning | [Paper](https://arxiv.org/abs/1805.05377), [Data](https://allenai.org/data/quarel) |
| **OpenBookQA** | Science QA | [Paper](https://arxiv.org/abs/1809.02789), [Data](https://allenai.org/data/open-book-qa) |
| **QASC** | Multi-hop Science | [Paper](https://arxiv.org/abs/1910.11473), [Data](https://allenai.org/data/qasc) |
| **GSM8K** | Math Problems | [Paper](https://arxiv.org/abs/2110.14168), [Data](https://github.com/openai/grade-school-math) |
| **Causal Understanding** | Causal Reasoning | [Paper](https://arxiv.org/abs/2206.07682), [Data](https://github.com/google/BIG-bench) |

All datasets use silver rationales generated by GPT-3 (Text-Davinci-003).

## Hyperparameters

| Parameter | Default | Range | Description |
|-----------|---------|-------|-------------|
| `beta` | 0.1 | 0.01-0.5 | DPO temperature |
| `lambda_lm` | 1.0 | 0.5-2.0 | Language model loss weight |
| `lambda_ie` | 1.0 | 0.5-2.0 | Indirect effect loss weight |
| `lambda_margin` | 1.0 | 0.5-2.0 | Margin ranking loss weight |
| `learning_rate` | 5e-5 | 1e-5 to 1e-4 | Optimizer learning rate |

## Loss Functions

FRODO uses two modules:

**Inference Module**: DPO Loss
```
L_DPO = -log(σ(β * (log π_θ(r_w|x) - log π_ref(r_w|x) - log π_θ(r_l|x) + log π_ref(r_l|x))))
```

**Reasoning Module**: Combined Loss
```
L_PREF = λ_LM * L_LM + λ_IE * L_IE + λ_MR * L_MR
```

See `src/frodo.py` for implementation details.

## Citation

```bibtex
@inproceedings{paul2024making,
  title={Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning},
  author={Paul, Debjit and West, Robert and Bosselut, Antoine and Faltings, Boi},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2024},
  year={2024}
}
```

## Contact

- Issues: [GitHub Issues](https://github.com/epfl-nlp/Causal_CoT/issues)
- Email: debjit.paul@epfl.ch
